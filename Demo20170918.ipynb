{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用正規表達法斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['氣候變遷讓登革熱成為各國公共衛生的燙手山芋',\n",
       " '前年在國內造成4萬多例感染',\n",
       " '228人死亡的嚴重疫情',\n",
       " '尤其是台南市成疫情重災區',\n",
       " '時任台南市長的行政院長賴清德今早出席',\n",
       " '登革熱國際防治論壇',\n",
       " '',\n",
       " '表達對防疫的重視',\n",
       " '他強調',\n",
       " '登革熱防疫須有對策',\n",
       " '否則疫情不會僅限於南台灣',\n",
       " '國內死亡病例有高齡',\n",
       " '患慢性病等特性',\n",
       " '與東南亞國家不同',\n",
       " '台南經驗可供疫苗研發參考',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "article = '''氣候變遷讓登革熱成為各國公共衛生的燙手山芋，前年在國內造成4萬多例感染，228人死亡的嚴重疫情，尤其是台南市成疫情重災區，時任台南市長的行政院長賴清德今早出席「登革熱國際防治論壇」，表達對防疫的重視。他強調，登革熱防疫須有對策，否則疫情不會僅限於南台灣，國內死亡病例有高齡、患慢性病等特性，與東南亞國家不同，台南經驗可供疫苗研發參考。'''\n",
    "re.split('，|。|「|」|、', article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝 Jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in c:\\programdata\\anaconda3\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "! pip install jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Jieba 切詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.153 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大\n",
      "巨蛋\n",
      "案對\n",
      "市府\n",
      "同仁\n",
      "下\n",
      "封口令\n",
      "？\n",
      "　\n",
      "柯\n",
      "P\n",
      "否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "for w in jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\"):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大\n",
      "巨蛋\n",
      "案\n",
      "對\n",
      "市府\n",
      "同仁\n",
      "下\n",
      "封口\n",
      "封口令\n",
      "口令\n",
      "\n",
      "\n",
      "\n",
      "柯\n",
      "P\n",
      "否\n",
      "認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "for w in jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=True):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.114 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['大', '巨蛋', '案對', '市府', '同仁', '下', '封口令', '？', '\\u3000', '柯', 'P', '否認']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "ary = []\n",
    "for w in jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\"):\n",
    "    ary.append(w)\n",
    "ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['大', '巨蛋', '案對', '市府', '同仁', '下', '封口令', '？', '\\u3000', '柯', 'P', '否認']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['大巨蛋', '案對', '市府', '同仁', '下', '封口令', '？', '\\u3000', '柯P', '否認']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## add_word 只有暫時生效\n",
    "jieba.add_word('大巨蛋')\n",
    "jieba.add_word('柯P')\n",
    "[w for w in jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\User\\itritm\\dict.txt ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.uf0178d4b7c79c465ac9d115367f9739d.cache\n",
      "Loading model cost 0.005 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋/案對/市府/同仁下/封口令/？/　/柯P/否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.set_dictionary('dict.txt')\n",
    "[w for w in jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")]\n",
    "'/'.join([w for w in jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")])\n",
    "print('/'.join([w for w in jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['大巨蛋', '案對', '市府', '同仁下', '封口令', '？', ' ', '柯P', '否認']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 1:\n",
    "sentence = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "' '.join(sentence.split())\n",
    "[w for w in jieba.cut(' '.join(sentence.split()))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['大巨蛋', '案對', '市府', '同仁下', '封口令', '？', '', '柯P', '否認']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method2\n",
    "sentence = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "[w.strip() for w in jieba.cut(' '.join(sentence.split()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋 nr\n",
      "案 ng\n",
      "對 p\n",
      "市府 n\n",
      "同仁 n\n",
      "下封 v\n",
      "口令 n\n",
      "？ x\n",
      "　 x\n",
      "柯P x\n",
      "否認 v\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "jieba.add_word('大巨蛋', 100, 'nr' )\n",
    "words = pseg.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")\n",
    "\n",
    "for w in words:\n",
    "    print(w.word, w.flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋 0 3\n",
      "案對 3 5\n",
      "市府 5 7\n",
      "同仁下 7 10\n",
      "封口令 10 13\n",
      "？ 13 14\n",
      "　 14 15\n",
      "柯P 15 17\n",
      "否認 17 19\n"
     ]
    }
   ],
   "source": [
    "words = jieba.tokenize(\"大巨蛋案對市府同仁下封口令？　柯P否認\")\n",
    "\n",
    "for tw in words:\n",
    "    print(tw[0], tw[1], tw[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "封口令\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "tags = jieba.analyse.extract_tags(\"大巨蛋案對市府同仁下封口令？　柯P否認\", 1)\n",
    "print(\",\".join(tags))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拿掉中間空白"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i love this book'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '        i                      love                this        book'\n",
    "sentence.split()\n",
    "' '.join(sentence.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 獲取新詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "北韓\n",
      "川普\n",
      "美國\n",
      "金正恩\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "res =  requests.get('http://news.ltn.com.tw/news/world/breakingnews/2196565')\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "for keyword in soup.select('.keyword a'):\n",
    "    print(keyword.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那我\n",
      "我們\n",
      "們酸\n",
      "酸民\n",
      "民婉\n",
      "婉君\n",
      "君也\n",
      "也可\n",
      "可以\n",
      "以報\n",
      "報名\n",
      "名嗎\n"
     ]
    }
   ],
   "source": [
    "# 2-gram : bi-gram\n",
    "sentence = '那我們酸民婉君也可以報名嗎'\n",
    "for i in range(0, len(sentence) - 2 + 1):\n",
    "    #print(i, i + 2)\n",
    "    print(sentence[i:i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那我們\n",
      "我們酸\n",
      "們酸民\n",
      "酸民婉\n",
      "民婉君\n",
      "婉君也\n",
      "君也可\n",
      "也可以\n",
      "可以報\n",
      "以報名\n",
      "報名嗎\n"
     ]
    }
   ],
   "source": [
    "# 3-gram : tri-gram\n",
    "sentence = '那我們酸民婉君也可以報名嗎'\n",
    "for i in range(0, len(sentence) - 3 + 1):\n",
    "    #print(i, i + 3)\n",
    "    print(sentence[i:i+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['那我', '我們', '們酸', '酸民', '民婉', '婉君', '君也', '也可', '可以', '以報', '報名', '名嗎']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ngram(sentence, n = 2):\n",
    "    ary = []\n",
    "    for i in range(0, len(sentence) - n + 1):\n",
    "        ary.append(sentence[i:i+n])\n",
    "    return ary\n",
    "\n",
    "\n",
    "ngram('那我們酸民婉君也可以報名嗎')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Counter 統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3, 2: 4, 3: 2})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= [1,2,3,1,2,2,3,1,2]\n",
    "from collections import Counter\n",
    "c = Counter(a)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram(sentence, n = 2):\n",
    "    ary = []\n",
    "    for i in range(0, len(sentence) - n + 1):\n",
    "        ary.append(sentence[i:i+n])\n",
    "    return Counter(ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'也可以': 1,\n",
       "         '以報名': 1,\n",
       "         '們酸民': 1,\n",
       "         '可以報': 1,\n",
       "         '君也可': 1,\n",
       "         '報名嗎': 1,\n",
       "         '婉君也': 1,\n",
       "         '我們酸': 1,\n",
       "         '民婉君': 1,\n",
       "         '那我們': 1,\n",
       "         '酸民婉': 1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram('那我們酸民婉君也可以報名嗎', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article = '''氣候變遷讓登革熱成為各國公共衛生的燙手山芋，前年在國內造成4萬多例感染，228人死亡的嚴重疫情，尤其是台南市成疫情重災區，時任台南市長的行政院長賴清德今早出席「登革熱國際防治論壇」，表達對防疫的重視。他強調，登革熱防疫須有對策，否則疫情不會僅限於南台灣，國內死亡病例有高齡、患慢性病等特性，與東南亞國家不同，台南經驗可供疫苗研發參考。\n",
    "賴清德表示，蚊子散佈疾病造成人類喪生的威脅比世界大戰還大，前年擔任台南市長面臨有史以來最嚴重的登革熱疫情，共有2萬多例病例，半數是9歲以下、55歲以上，且流行病學調查顯示，當時台南的登革熱死亡有108例，平均年齡約70歲，其中90％至少患1種慢性病。\n",
    "去年6月衛福部疾管署與美國國家衛生研究院簽署合作備忘錄，將共同研發全球首款針對高齡族群的登革熱疫苗，將在台進行臨床試驗。賴說，目前政府的防疫作為主要是化學防治、孳生源清除，若登革熱疫苗能成功上市，防疫會更有效率。（蔡明樺／台北報導）'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('登革', 7),\n",
       " ('革熱', 7),\n",
       " ('台南', 5),\n",
       " ('疫情', 4),\n",
       " ('防疫', 4),\n",
       " ('死亡', 3),\n",
       " ('南市', 3),\n",
       " ('疫苗', 3),\n",
       " ('的登', 3),\n",
       " ('熱疫', 3)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = ngram(article, 2)\n",
    "res.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('登革熱', 7),\n",
       " ('台南市', 3),\n",
       " ('的登革', 3),\n",
       " ('革熱疫', 3),\n",
       " ('，前年', 2),\n",
       " ('萬多例', 2),\n",
       " ('疫情，', 2),\n",
       " ('任台南', 2),\n",
       " ('南市長', 2),\n",
       " ('賴清德', 2)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = ngram(article, 3)\n",
    "res.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['氣候變遷讓登革熱成為各國公共衛生的燙手山芋',\n",
       " '前年在國內造成4萬多例感染',\n",
       " '228人死亡的嚴重疫情',\n",
       " '尤其是台南市成疫情重災區',\n",
       " '時任台南市長的行政院長賴清德今早出席',\n",
       " '登革熱國際防治論壇',\n",
       " '',\n",
       " '表達對防疫的重視',\n",
       " '他強調',\n",
       " '登革熱防疫須有對策',\n",
       " '否則疫情不會僅限於南台灣',\n",
       " '國內死亡病例有高齡',\n",
       " '患慢性病等特性',\n",
       " '與東南亞國家不同',\n",
       " '台南經驗可供疫苗研發參考',\n",
       " '',\n",
       " '賴清德表示',\n",
       " '蚊子散佈疾病造成人類喪生的威脅比世界大戰還大',\n",
       " '前年擔任台南市長面臨有史以來最嚴重的登革熱疫情',\n",
       " '共有2萬多例病例',\n",
       " '半數是9歲以下',\n",
       " '55歲以上',\n",
       " '且流行病學調查顯示',\n",
       " '當時台南的登革熱死亡有108例',\n",
       " '平均年齡約70歲',\n",
       " '其中90％至少患1種慢性病',\n",
       " '',\n",
       " '去年6月衛福部疾管署與美國國家衛生研究院簽署合作備忘錄',\n",
       " '將共同研發全球首款針對高齡族群的登革熱疫苗',\n",
       " '將在台進行臨床試驗',\n",
       " '賴說',\n",
       " '目前政府的防疫作為主要是化學防治',\n",
       " '孳生源清除',\n",
       " '若登革熱疫苗能成功上市',\n",
       " '防疫會更有效率',\n",
       " '',\n",
       " '蔡明樺',\n",
       " '台北報導',\n",
       " '']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.split('，|。|「|」|、|\\n|／|\"|（|）', article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'若能成功上市'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '若登革熱疫苗能成功上市'\n",
    "''.join(a.split('登革熱'))\n",
    "\n",
    "\n",
    "for w in ['登革熱', '疫苗']:\n",
    "    a = ''.join(a.split(w))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeKey(sentence, keywords):\n",
    "    for keyword in keywords:\n",
    "        sentence = ''.join(a.split(keyword))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'若能成功上市'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeKey('若登革熱疫苗能成功上市',['登革熱','疫苗'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 長詞優先法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram(sentence, n = 2):\n",
    "    ary = []\n",
    "    for i in range(0, len(sentence) - n + 1):\n",
    "        ary.append(sentence[i:i+n])\n",
    "    return Counter(ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeKey(sentence, keywords):\n",
    "    for keyword in keywords:\n",
    "        sentence = ''.join(sentence.split(keyword))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "article = '''氣候變遷讓登革熱成為各國公共衛生的燙手山芋，前年在國內造成4萬多例感染，228人死亡的嚴重疫情，尤其是台南市成疫情重災區，時任台南市長的行政院長賴清德今早出席「登革熱國際防治論壇」，表達對防疫的重視。他強調，登革熱防疫須有對策，否則疫情不會僅限於南台灣，國內死亡病例有高齡、患慢性病等特性，與東南亞國家不同，台南經驗可供疫苗研發參考。\n",
    "賴清德表示，蚊子散佈疾病造成人類喪生的威脅比世界大戰還大，前年擔任台南市長面臨有史以來最嚴重的登革熱疫情，共有2萬多例病例，半數是9歲以下、55歲以上，且流行病學調查顯示，當時台南的登革熱死亡有108例，平均年齡約70歲，其中90％至少患1種慢性病。\n",
    "去年6月衛福部疾管署與美國國家衛生研究院簽署合作備忘錄，將共同研發全球首款針對高齡族群的登革熱疫苗，將在台進行臨床試驗。賴說，目前政府的防疫作為主要是化學防治、孳生源清除，若登革熱疫苗能成功上市，防疫會更有效率。（蔡明樺／台北報導）'''\n",
    "sentence_ary = re.split('，|。|「|」|、|\\n|／|\"|（|）', article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords    = []\n",
    "term_length = 4\n",
    "threshold   = 5\n",
    "\n",
    "word_counter = Counter()\n",
    "\n",
    "for sentence in sentence_ary:\n",
    "    text = removeKey(sentence, keywords)\n",
    "    word_counter = word_counter + ngram(text, term_length)\n",
    "    \n",
    "for word, value in word_counter.items():\n",
    "    #print(word, value)\n",
    "    if value >= threshold:\n",
    "        keywords.append(word)\n",
    "        \n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('登革熱', 7),\n",
       " ('台南市', 3),\n",
       " ('的登革', 3),\n",
       " ('革熱疫', 3),\n",
       " ('，前年', 2),\n",
       " ('萬多例', 2),\n",
       " ('疫情，', 2),\n",
       " ('任台南', 2),\n",
       " ('南市長', 2),\n",
       " ('賴清德', 2)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(article, 3).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['任台南市',\n",
       " '台南市長',\n",
       " '的登革熱',\n",
       " '登革熱疫',\n",
       " '革熱疫苗',\n",
       " '若能成',\n",
       " '能成功',\n",
       " '成功上',\n",
       " '功上市',\n",
       " '若能',\n",
       " '能成']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords    = []\n",
    "threshold   = 2\n",
    "\n",
    "for term_length in range(4, 1, -1):\n",
    "    word_counter = Counter()\n",
    "\n",
    "    for sentence in sentence_ary:\n",
    "        text = removeKey(sentence, keywords)\n",
    "        word_counter = word_counter + ngram(text, term_length)\n",
    "\n",
    "    for word, value in word_counter.items():\n",
    "        #print(word, value)\n",
    "        if value >= threshold:\n",
    "            keywords.append(word)\n",
    "        \n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "news = pandas.read_excel('news.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "article = ''\n",
    "for rec in news.iterrows():\n",
    "    article =  article + rec[1].content + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_ary = re.split('，|。|「|」|、|\\n|／|\"|（|）|\\)|：|《', article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram(sentence, n = 2):\n",
    "    ary = []\n",
    "    for i in range(0, len(sentence) - n + 1):\n",
    "        ary.append(sentence[i:i+n])\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['即時新聞', '時新聞中', '新聞中心', '綜合報導', 'one ', '綜合外電', '合外電報', '外電報導', '出版時間', '更新時間', '新增影片', '台北報導', '突發中心', '顛覆國家', '覆國家政', '國家政權', 'iPho', 'Phon', 'hone', '今天上午', '詹詠然', '世大運', '201', '粉絲團', '自己的', '0萬元', '...', '100', '的問題', '500', '沒想到', '00萬', '李明哲', '彭宇華', '蔡英文', 'iPh', '消費者', '00元', '0公里', '氣象局', '上警報', '200', '派出所', '姓男子', '在臉書', '從宜花', '行政院', '賴清德', '新北市', '地檢署', '台北市', '000', '有網友', '東南亞', '檢察官', '文言文', '童子賢', '立法院', '腳踏車']\n"
     ]
    }
   ],
   "source": [
    "keywords    = []\n",
    "threshold   = 20\n",
    "\n",
    "for term_length in range(4, 2, -1):\n",
    "    #print(term_length)\n",
    "    ngram_list = []\n",
    "\n",
    "    for sentence in sentence_ary:\n",
    "        text = removeKey(sentence, keywords)\n",
    "        #print(ngram(text, term_length))\n",
    "        ngram_list.extend(ngram(text, term_length))\n",
    "        \n",
    "        \n",
    "    word_counter = Counter(ngram_list)\n",
    "    for word, value in word_counter.items():\n",
    "    #    #print(word, value)\n",
    "        if value >= threshold:\n",
    "            keywords.append(word)\n",
    "    #print(keywords)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "即時新聞\n",
      "時新聞中\n",
      "新聞中心\n",
      "綜合報導\n",
      "合報導)\n",
      "one \n",
      "綜合外電\n",
      "合外電報\n",
      "外電報導\n",
      "出版時間\n",
      "版時間：\n",
      "時間：0\n",
      "更新時間\n",
      "新時間：\n",
      "時間：1\n",
      "更新：新\n",
      "新：新增\n",
      "新增影片\n",
      "台北報導\n",
      "突發中心\n",
      "顛覆國家\n",
      "覆國家政\n",
      "國家政權\n",
      "iPho\n",
      "Phon\n",
      "hone\n",
      "今天上午\n"
     ]
    }
   ],
   "source": [
    "for keyword in keywords:\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字雲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "登革熱 7\n",
      "疫情 3\n",
      "台南 3\n",
      "前年 2\n",
      "國內 2\n",
      "造成 2\n",
      "萬多例 2\n",
      "嚴重 2\n",
      "台南市 2\n",
      "死亡 2\n",
      "病例 2\n",
      "性病 2\n",
      "疫苗 2\n",
      "研發 2\n",
      "氣候 1\n",
      "變遷 1\n",
      "成為 1\n",
      "各國 1\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.add_word('登革熱')\n",
    "article = '''氣候變遷讓登革熱成為各國公共衛生的燙手山芋，前年在國內造成4萬多例感染，228人死亡的嚴重疫情，尤其是台南市成疫情重災區，時任台南市長的行政院長賴清德今早出席「登革熱國際防治論壇」，表達對防疫的重視。他強調，登革熱防疫須有對策，否則疫情不會僅限於南台灣，國內死亡病例有高齡、患慢性病等特性，與東南亞國家不同，台南經驗可供疫苗研發參考。\n",
    "賴清德表示，蚊子散佈疾病造成人類喪生的威脅比世界大戰還大，前年擔任台南市長面臨有史以來最嚴重的登革熱疫情，共有2萬多例病例，半數是9歲以下、55歲以上，且流行病學調查顯示，當時台南的登革熱死亡有108例，平均年齡約70歲，其中90％至少患1種慢性病。\n",
    "去年6月衛福部疾管署與美國國家衛生研究院簽署合作備忘錄，將共同研發全球首款針對高齡族群的登革熱疫苗，將在台進行臨床試驗。賴說，目前政府的防疫作為主要是化學防治、孳生源清除，若登革熱疫苗能成功上市，防疫會更有效率。（蔡明樺／台北報導）'''\n",
    "\n",
    "from collections import Counter\n",
    "c = Counter([ele for ele in jieba.cut(article)])\n",
    "for word, cnt in c.most_common(30):\n",
    "    if len(word) >= 2:\n",
    "        print(word, cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF 計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, abb, abc = ['a'], ['a', 'b', 'b'], ['a', 'b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.270310072072\n",
      "0.0\n",
      "0.135155036036\n",
      "0.366204096223\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "#tfidf('a', a, D)\n",
    "tf  = 1/1\n",
    "idf = sp.log(3 / 3)\n",
    "print(tf * idf)\n",
    "\n",
    "#tfidf('a', abb, D)\n",
    "tf  = 1 / 3\n",
    "idf = sp.log(3/3)\n",
    "print(tf * idf)\n",
    "\n",
    "#tfidf('b', abb, D)\n",
    "tf  = 2 / 3\n",
    "idf = sp.log(3/2)\n",
    "print(tf * idf)\n",
    "\n",
    "#tfidf('a', abc, D)\n",
    "tf  = 1 / 3\n",
    "idf = sp.log(3/3)\n",
    "print(tf * idf)\n",
    "\n",
    "#tfidf('b', abc, D)\n",
    "tf  = 1 / 3\n",
    "idf = sp.log(3/2)\n",
    "print(tf * idf)\n",
    "\n",
    "#tfidf('c', abc, D)\n",
    "tf  = 1 / 3\n",
    "idf = sp.log(3/1)\n",
    "print(tf * idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36620409622270322"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf(term, document, Documents):\n",
    "    tf  =  document.count(term)  / len(document)\n",
    "    idf =  sp.log(len(Documents) / len([d for d in Documents if term in d]) ) \n",
    "    return tf * idf\n",
    "\n",
    "tfidf('a',   a, [a,abb,abc])\n",
    "tfidf('a', abb, [a,abb,abc])\n",
    "tfidf('b', abb, [a,abb,abc])\n",
    "tfidf('a', abc, [a,abb,abc])\n",
    "tfidf('b', abc, [a,abb,abc])\n",
    "tfidf('c', abc, [a,abb,abc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 求得詞頻矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['【 更 新 】 柯P ： 洪智坤 洩漏 公文 案還 沒 看 到 公文 \\u3000 今處理',\n",
       " '留 洪智坤   柯 ： 殘障 求職 不易',\n",
       " '人事 處議 處 洪智坤 \\u3000 柯P ： 不清楚 議處 結果']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.add_word('洪智坤')\n",
    "jieba.add_word('公文')\n",
    "jieba.add_word('殘障')\n",
    "jieba.add_word('求職')\n",
    "ary = ['【更新】柯P：洪智坤洩漏公文案還沒看到公文　今處理',\n",
    "       '留洪智坤 柯：殘障求職不易',\n",
    "       '人事處議處洪智坤　柯P：不清楚議處結果']\n",
    "\n",
    "corpus = []\n",
    "for title in ary:\n",
    "    corpus.append(' '.join(jieba.cut(title)))\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 14)\n",
      "['不易', '不清楚', '人事', '今處理', '公文', '柯p', '案還', '殘障', '求職', '洩漏', '洪智坤', '結果', '處議', '議處']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 14)\n",
      "['不易', '不清楚', '人事', '今處理', '公文', '柯p', '案還', '殘障', '求職', '洩漏', '洪智坤', '結果', '處議', '議處']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.35517252,  0.71034504,\n",
       "         0.27011786,  0.35517252,  0.        ,  0.        ,  0.35517252,\n",
       "         0.20977061,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.54645401,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.54645401,  0.54645401,  0.        ,\n",
       "         0.32274454,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.41074684,  0.41074684,  0.        ,  0.        ,\n",
       "         0.31238356,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.2425937 ,  0.41074684,  0.41074684,  0.41074684]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3166247903554"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "a = np.array([0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0, 0, 0])\n",
    "b = np.array([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0])\n",
    "\n",
    "math.sqrt(sum((a - b) * (a - b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = '柯文哲去大巨蛋'\n",
    "b = '柯文哲跟大巨蛋還有趙藤雄的愛怨情仇'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   柯文哲 大巨蛋 趙藤雄 愛怨情仇\n",
    "a    1      1     0      0\n",
    "b    1      1     1      1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.449489742783178"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,1,0,0])\n",
    "b = np.array([1,1,1,1])\n",
    "\n",
    "math.sqrt(sum((a - b) * (a - b)))\n",
    "\n",
    "a = np.array([1,1,0,0,0,0,0,0])\n",
    "b = np.array([1,1,1,1,1,1,1,1])\n",
    "\n",
    "math.sqrt(sum((a - b) * (a - b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算餘弦相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.06770232,  0.1352694 ],\n",
       "       [ 0.06770232,  1.        ,  0.07829579],\n",
       "       [ 0.1352694 ,  0.07829579,  1.        ]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(corpus)\n",
    "\n",
    "cosine_similarities = cosine_similarity(tfidf)\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找出相似新聞文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>clicked</th>\n",
       "      <th>content</th>\n",
       "      <th>dt</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>體育</td>\n",
       "      <td>0</td>\n",
       "      <td>台灣女將詹詠然在美國網球公開賽奪下女雙冠軍，但仍因台北世大運棄賽，飽受批評。BBS站批踢踢的...</td>\n",
       "      <td>2017-09-11 14:12:00</td>\n",
       "      <td>暗批詹詠然沒誠信！PTT創世神：代言什麼都抵制</td>\n",
       "      <td>http://www.appledaily.com.tw/realtimenews/arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>財經</td>\n",
       "      <td>9819</td>\n",
       "      <td>（新增郭董特助胡國輝今天談話、調整標題）彭博報導，在日本東芝本周三將召開董事會敲定晶片事業最...</td>\n",
       "      <td>2017-09-11 14:10:00</td>\n",
       "      <td>郭董周三決戰前再放話　鴻海追東芝出價2.1兆日圓</td>\n",
       "      <td>http://www.appledaily.com.tw/realtimenews/arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>娛樂</td>\n",
       "      <td>5631</td>\n",
       "      <td>（新增：照片、內文）韓國27歲男星姜河那2013年以《繼承者們》走紅，去年在《步步驚心：麗》...</td>\n",
       "      <td>2017-09-11 14:10:00</td>\n",
       "      <td>撇入伍前夕祕會IU　姜河那IG曬剃頭照告別</td>\n",
       "      <td>http://www.appledaily.com.tw/realtimenews/arti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category  clicked                                            content  \\\n",
       "0       體育        0  台灣女將詹詠然在美國網球公開賽奪下女雙冠軍，但仍因台北世大運棄賽，飽受批評。BBS站批踢踢的...   \n",
       "1       財經     9819  （新增郭董特助胡國輝今天談話、調整標題）彭博報導，在日本東芝本周三將召開董事會敲定晶片事業最...   \n",
       "2       娛樂     5631  （新增：照片、內文）韓國27歲男星姜河那2013年以《繼承者們》走紅，去年在《步步驚心：麗》...   \n",
       "\n",
       "                   dt                     title  \\\n",
       "0 2017-09-11 14:12:00   暗批詹詠然沒誠信！PTT創世神：代言什麼都抵制   \n",
       "1 2017-09-11 14:10:00  郭董周三決戰前再放話　鴻海追東芝出價2.1兆日圓   \n",
       "2 2017-09-11 14:10:00     撇入伍前夕祕會IU　姜河那IG曬剃頭照告別   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.appledaily.com.tw/realtimenews/arti...  \n",
       "1  http://www.appledaily.com.tw/realtimenews/arti...  \n",
       "2  http://www.appledaily.com.tw/realtimenews/arti...  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "news = pandas.read_excel('news.xlsx')\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "corpus = []\n",
    "titles = []\n",
    "for rec in news.iterrows():\n",
    "    corpus.append(' '.join(jieba.cut(rec[1].content)))\n",
    "    titles.append(rec[1].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.00779497,  0.01039051, ...,  0.02237498,\n",
       "         0.00350381,  0.01527563],\n",
       "       [ 0.00779497,  1.        ,  0.01174235, ...,  0.00581945,\n",
       "         0.0012697 ,  0.01950113],\n",
       "       [ 0.01039051,  0.01174235,  1.        , ...,  0.00460205,\n",
       "         0.00316098,  0.01178243],\n",
       "       ..., \n",
       "       [ 0.02237498,  0.00581945,  0.00460205, ...,  1.        ,\n",
       "         0.00151298,  0.00607013],\n",
       "       [ 0.00350381,  0.0012697 ,  0.00316098, ...,  0.00151298,\n",
       "         1.        ,  0.01449557],\n",
       "       [ 0.01527563,  0.01950113,  0.01178243, ...,  0.00607013,\n",
       "         0.01449557,  1.        ]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(corpus)\n",
    "\n",
    "cosine_similarities = cosine_similarity(tfidf)\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles_ary = np.array(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "暗批詹詠然沒誠信！PTT創世神：代言什麼都抵制 1.0\n",
      "他尊重詹詠然選擇　「嫁給富人放棄窮光蛋」 0.10343532895\n",
      "詹詠然道歉你接受嗎？　網友12字神翻譯 0.0757411005594\n"
     ]
    }
   ],
   "source": [
    "orders = cosine_similarities[0].argsort()[::-1]\n",
    "for p in orders:\n",
    "    if  cosine_similarities[0][p] > 0.07:\n",
    "        print(titles_ary[p], cosine_similarities[0][p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查詢文章: 爛醉男譙警四字經　酒醒掰「甘草二兩」\n",
      "相似文章 藏毒裝傻　遇警小碎步撒嬌求情 0.113370176245\n",
      "相似文章 暖心女警一句話　毒蟲悔改「不吸毒了！」 0.098588882687\n"
     ]
    }
   ],
   "source": [
    "def getSimiliarArticle(i):\n",
    "    print('查詢文章:',titles_ary[i])\n",
    "    orders = cosine_similarities[i].argsort()[::-1]\n",
    "    for p in orders[1:]:\n",
    "        if  cosine_similarities[i][p] > 0.07:\n",
    "            print('相似文章', titles_ary[p], cosine_similarities[i][p])\n",
    "getSimiliarArticle(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([2,5,1,3,4])\n",
    "a.sort()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, 4, 1], dtype=int64)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([2,5,1,3,4])\n",
    "a.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dropbox\n",
      "  Downloading dropbox-8.1.0-py3-none-any.whl (409kB)\n",
      "Requirement already satisfied: requests!=2.16.0,!=2.16.1,!=2.6.1,>=2.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from dropbox)\n",
      "Requirement already satisfied: six>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from dropbox)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from dropbox)\n",
      "Requirement already satisfied: idna<2.6,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests!=2.16.0,!=2.16.1,!=2.6.1,>=2.5.1->dropbox)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests!=2.16.0,!=2.16.1,!=2.6.1,>=2.5.1->dropbox)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests!=2.16.0,!=2.16.1,!=2.6.1,>=2.5.1->dropbox)\n",
      "Installing collected packages: dropbox\n",
      "Successfully installed dropbox-8.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullAccount(account_id='dbid:AACwOVPyOea2APkiEiVdHVspbRqDEtadhxw', name=Name(given_name='David', surname='Chiu', familiar_name='Chiu David', display_name='Chiu David', abbreviated_name='CD'), email='david@largitdata.com', email_verified=True, disabled=False, locale='zh-TW', referral_link='https://db.tt/rCzKvypNYl', is_paired=False, account_type=AccountType('basic', None), profile_photo_url=None, country='TW', team=None, team_member_id=None)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dropbox\n",
    "dbx = dropbox.Dropbox(\"P0WwXruYdEAAAAAAAAAAPqADpa05avlMfXW2DhxDponbgq8Or35N_F6MIcyPelKn\")\n",
    "dbx.users_get_current_account()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
